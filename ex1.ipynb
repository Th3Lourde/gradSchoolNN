{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log, exp\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataRaw = pd.read_csv('Admission_Predict.csv')\n",
    "dataRaw.head()\n",
    "# del dataRaw['Serial No.'] # Serves as a unique identifier, not needed for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataRaw.iloc[:,1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataRaw.iloc[:,1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataRaw.iloc[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataRaw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk =  np.random.rand(len(dataRaw)) < 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True,  True, False,  True, False,  True,\n",
       "        True,  True, False,  True,  True, False,  True, False,  True,\n",
       "        True, False, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "        True,  True,  True,  True, False,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True, False, False,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "       False,  True,  True,  True,  True, False, False,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True,  True, False, False,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "       False,  True, False,  True, False,  True, False, False,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True, False, False,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "        True, False,  True, False,  True,  True, False,  True,  True,\n",
       "       False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "       False,  True,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "       False, False, False, False])"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = dataRaw[msk]\n",
    "testData = dataRaw[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, m, s):\n",
    "    return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk =  np.random.rand(len(dataRaw)) < 0.8\n",
    "\n",
    "trainData = dataRaw[msk]\n",
    "validData = dataRaw[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(trainData.iloc[:,:-1].values, dtype=torch.float)\n",
    "y_train = torch.tensor(trainData.iloc[:,-1:].values, dtype=torch.float)\n",
    "\n",
    "x_valid = torch.tensor(validData.iloc[:,:-1].values, dtype=torch.float)\n",
    "y_valid = torch.tensor(validData.iloc[:,-1:].values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train-x_train.min())/(x_train.max()-x_train.min())\n",
    "x_valid = (x_valid-x_valid.min())/(x_valid.max()-x_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1863), tensor(0.3225))"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean,train_std = x_train.mean(),x_train.std()\n",
    "train_mean,train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "# NB: Use training, not validation mean for validation set\n",
    "x_valid = normalize(x_valid, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.0058e-07), tensor(1.))"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean,train_std = x_train.mean(),x_train.std()\n",
    "train_mean,train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __call__(self, y, yhat):\n",
    "        self.y = y\n",
    "        self.yHat = yhat\n",
    "        tmp = (-1)*y*log(max(yhat, 0.00000000000000000001)) - (1-y)*log(max(1-yhat,0.00000000000000000001))\n",
    "        return tmp\n",
    "    \n",
    "    def backward(self, grad):\n",
    "        '''\n",
    "        [(-y)/(yHat) - (1-y)/(1-yHat)]\n",
    "        '''\n",
    "        left = ((-1)*(self.y))/(self.yHat)\n",
    "        right = (1-self.y)/(1-self.yHat)\n",
    "        \n",
    "        grad *= (left-right)\n",
    "        \n",
    "        return grad\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __call__(self, x):\n",
    "        self.x = x\n",
    "#         print(\"type of input is: {}\".format(type(x)))\n",
    "#         print(\"dim of input is: {}\".format(x.dim()))\n",
    "#         print(\"shape of input is: {}\".format(x.shape))\n",
    "#         print(\"input is: {}\".format(x))\n",
    "        return 1/(1+torch.exp((-1)*x)) \n",
    "    \n",
    "    def backward(self, grad):\n",
    "        '''\n",
    "        (e^-x)/((1+e^-x)^2)\n",
    "        '''\n",
    "        top = torch.exp((-1)*self.x)\n",
    "        bottom = (1+torch.exp((-1)*self.x))**2\n",
    "        \n",
    "        grad *= top/bottom\n",
    "        \n",
    "        return grad\n",
    "    \n",
    "    def refresh(self):\n",
    "        self.x = 0\n",
    "        \n",
    "        \n",
    "    def update(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, m, n, alpha):\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "#         self.w = torch.randn(m,n)*math.sqrt(2/m)\n",
    "        self.w = torch.randn(m,n)\n",
    "#         self.b = torch.zeros(n)\n",
    "        self.b = torch.randn(n)\n",
    "        \n",
    "        self.lr = alpha\n",
    "        self.count = 0\n",
    "        self.nW = 1\n",
    "        self.nB = 1\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        self.inp = x\n",
    "        self.out = x@self.w + self.b \n",
    "        return x@self.w + self.b\n",
    "    \n",
    "    def refresh(self):\n",
    "        self.w = torch.randn(self.m,self.n)*math.sqrt(2/self.m)\n",
    "        self.b = torch.zeros(self.n)\n",
    "        \n",
    "        self.count = 0\n",
    "        self.nW = 1\n",
    "        self.nB = 1\n",
    "    \n",
    "    def backward(self, grad):\n",
    "        self.count += 1\n",
    "        self.nW += (self.inp.unsqueeze(-1) * grad.unsqueeze(0)).sum(0)\n",
    "        self.nB += grad.sum(0)\n",
    "\n",
    "        if grad.dim() == 0:\n",
    "            grad = grad.unsqueeze(-1)@self.w.t()\n",
    "            \n",
    "        elif grad.dim() != 0:\n",
    "            grad = grad@self.w.t()\n",
    "            \n",
    "        return grad\n",
    "    \n",
    "    def update(self):\n",
    "        self.nW /= self.count\n",
    "        self.nB /= self.count\n",
    "        \n",
    "        self.w = self.w.add_( (-1)*(self.lr)*(self.nW) )\n",
    "        self.b = self.b.add_( (-1)*(self.lr)*(self.nB) )\n",
    "        \n",
    "        self.count = 0\n",
    "        self.nW = 1\n",
    "        self.nB = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.activation = Sigmoid()\n",
    "        self.loss = LogisticRegression()\n",
    "        \n",
    "    def forwards(self, x):\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x) \n",
    "        \n",
    "        yHat = self.activation(x)\n",
    "        \n",
    "        self.yHat = yHat\n",
    "        \n",
    "        return yHat\n",
    "    \n",
    "    def getLoss(self, y):\n",
    "        return self.loss(y, self.yHat)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.grad = 1\n",
    "        \n",
    "        expandedLayers = [self.loss, self.activation]\n",
    "        \n",
    "        for layer in expandedLayers:\n",
    "            self.grad = layer.backward(self.grad)\n",
    "            \n",
    "        # Iterate through expanded layers\n",
    "        # Then iterate through the reverse of linear layers\n",
    "        for layer in reversed(self.layers):\n",
    "            self.grad = layer.backward(self.grad)\n",
    "            \n",
    "        return self.grad\n",
    "    \n",
    "    def update(self):\n",
    "        for layer in self.layers:\n",
    "            layer.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    def __init__(self, model, x_train, y_train, x_test, y_test, epochs=5):\n",
    "        self.model = model\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def train(self):\n",
    "        loss = 0\n",
    "        for epoch in range(self.epochs):\n",
    "            \n",
    "            for i in range(len(self.x_train)):\n",
    "#                 loss += self.model.forwards(self.x_train[i], self.y_train[i])\n",
    "\n",
    "                self.model.forwards(self.x_train[i])\n",
    "                \n",
    "                loss += self.model.getLoss(self.y_train[i])\n",
    "                \n",
    "                self.model.backward()\n",
    "                \n",
    "            print(\"[loss for epoch {}] {}\".format(epoch+1, loss/len(self.x_train)))\n",
    "            \n",
    "            loss = 0\n",
    "            self.model.update()\n",
    "            \n",
    "    def train_oneCycle(self):\n",
    "        loss = 0\n",
    "        for i in range(len(self.x_train)):\n",
    "#             loss += self.model.forwards(self.x_train[i], self.y_train[i])\n",
    "            \n",
    "            self.model.forwards(self.x_train[i])\n",
    "\n",
    "            loss += self.model.getLoss(self.y_train[i])\n",
    "            \n",
    "            self.model.backward()\n",
    "\n",
    "        print(\"[loss for train_oneCycle] {}\".format(loss/len(self.x_train)))\n",
    "\n",
    "        loss = 0\n",
    "        self.model.update()\n",
    "        \n",
    "    def train_xCycles(self, x):\n",
    "        for j in range(x):\n",
    "            loss = 0\n",
    "            for i in range(len(self.x_train)):\n",
    "#                 loss += self.model.forwards(self.x_train[i], self.y_train[i])\n",
    "                \n",
    "                self.model.forwards(self.x_train[i])\n",
    "\n",
    "                loss += self.model.getLoss(self.y_train[i])\n",
    "                \n",
    "                \n",
    "                self.model.backward()\n",
    "\n",
    "            print(\"[loss for {}] {}\".format(j, loss/len(self.x_train)))\n",
    "\n",
    "            loss = 0\n",
    "            self.model.update()\n",
    "            \n",
    "    def validate(self):\n",
    "        loss = 0\n",
    "        for i in range(len(self.x_test)):\n",
    "#             loss += self.model.forwards(self.x_test[i], self.y_test[i])\n",
    "            \n",
    "            self.model.forwards(self.x_test[i])\n",
    "\n",
    "            loss += self.model.getLoss(self.y_test[i])\n",
    "            \n",
    "        print(\"[test loss] {}\".format((loss/len(self.x_test))))\n",
    "        \n",
    "    def validateRMSE(self):\n",
    "        '''\n",
    "        (yHat-y)^2\n",
    "        ave\n",
    "        sqrt\n",
    "        '''\n",
    "        \n",
    "        ans = 0\n",
    "        residuals = 0\n",
    "        for i in range(len(self.x_test)):\n",
    "#             loss += self.model.forwards(self.x_test[i], self.y_test[i])\n",
    "            yHat = self.model.forwards(self.x_test[i])\n",
    "    \n",
    "            residuals += yHat-self.y_test[i]\n",
    "        \n",
    "        residuals *= residuals\n",
    "        residuals /= len(self.x_test)\n",
    "        return math.sqrt(residuals)\n",
    "    \n",
    "        \n",
    "        \n",
    "    def trainAndValidate(self):\n",
    "        self.train()\n",
    "        self.validate()\n",
    "        \n",
    "    def refresh(self):\n",
    "        for l in self.model.layers:\n",
    "            l.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "# model = Model([Linear(7, 25, alpha), Sigmoid(), Linear(25, 1, alpha)])\n",
    "model = Model([Linear(7, 25, alpha), Linear(25, 1, alpha)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(model, x_train, y_train, x_valid, y_valid, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refreshAndTrainOnce():\n",
    "    learn.refresh()\n",
    "    learn.train_oneCycle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loss for train_oneCycle] tensor([0.9742])\n"
     ]
    }
   ],
   "source": [
    "refreshAndTrainOnce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loss for train_oneCycle] tensor([0.7892])\n"
     ]
    }
   ],
   "source": [
    "learn.train_oneCycle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loss for 0] tensor([0.6009])\n",
      "[loss for 1] tensor([0.6080])\n",
      "[loss for 2] tensor([0.6288])\n",
      "[loss for 3] tensor([0.6658])\n"
     ]
    }
   ],
   "source": [
    "learn.train_xCycles(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loss for epoch 1] tensor([0.5971])\n",
      "[loss for epoch 2] tensor([0.5972])\n",
      "[loss for epoch 3] tensor([0.5973])\n",
      "[loss for epoch 4] tensor([0.5976])\n",
      "[loss for epoch 5] tensor([0.5980])\n"
     ]
    }
   ],
   "source": [
    "learn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test loss] tensor([0.7799])\n"
     ]
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8506973756437328"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validateRMSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "RMSE:\n",
    "sqrt(MSE)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
